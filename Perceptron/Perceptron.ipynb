{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schwartz-cnl/Computational-Neuroscience-Class/blob/main/Perceptron/Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron\n",
        "\n",
        "This is a simple example illustrating the classic perceptron algorithm. A linear decision function parametrized by the weight vector \"w\" and bias paramter \"b\" is learned by making small adjustements to these parameters every time the predicted label \"f_i\" mismatches the true label \"y_i\" of an input data point \"x_i\".\n",
        "\n",
        "The predicted label corresponds to the following function:\n",
        "\n",
        "             f_i = sign( < w, x_i> + b),\n",
        "\n",
        "where \"< . , . >\"  denotes the dot product operation.\n",
        "The update rule is given as follows:\n",
        "\n",
        "if \"y_i != f_i\" (predicted label f_i different from true label y_i) then\n",
        "\n",
        "          w <-- w + y_i*x_i; and  \n",
        "          b <-- b + y_i;\n",
        "\n",
        "else continue with next data sample The above process is repeated over the set of samples several times.\n",
        "\n",
        "If data points are linearly separable the above rule is guaranteed to converge in a finite number of iterations. Proof see: http://www.cs.columbia.edu/~mcollins/courses/6998-2012/notes/perc.converge.pdf\n",
        "\n",
        "\n",
        "2016 Luis G Sanchez Giraldo and Odelia Schwartz. Transcribed and modified to Python by Xu Pan, 2022."
      ],
      "metadata": {
        "id": "00PKsXoUmdOt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-7FvNGKmNWr"
      },
      "outputs": [],
      "source": [
        "# Construct a simple data set based on MNIST images\n",
        "# This is a data set of handwritten digits 0 to 9\n",
        "\n",
        "# Download MNIST dataset from keras\n",
        "\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "print(test_X.shape)\n",
        "print(test_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y are the digit labels\n",
        "print(train_y[0:10])"
      ],
      "metadata": {
        "id": "zjxqy6FprtBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort dataset by label.\n",
        "\n",
        "sorted_test_X =[[], [], [], [], [], [], [], [], [], []]\n",
        "for i, y in enumerate(test_y):\n",
        "  sorted_test_X[y].append(test_X[i,:,:])"
      ],
      "metadata": {
        "id": "sbIIcejmAAur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a simple two-class problem using images of digits 0 and 5 from\n",
        "# the MNIST test data set  \n",
        "pos_class = 0 # 3\n",
        "neg_class = 5"
      ],
      "metadata": {
        "id": "uyCeh08MBHqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get samples from positive and negative classes \n",
        "pos_data = np.array(sorted_test_X[pos_class])\n",
        "neg_data = np.array(sorted_test_X[neg_class])\n",
        "print(pos_data.shape)\n",
        "print(neg_data.shape)"
      ],
      "metadata": {
        "id": "JdEjh1RSCi-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at some digits from the classes\n",
        "# Look at different samples from each class (here plotted just the first; try others)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(pos_data[0,:,:], cmap='binary')\n",
        "plt.show()\n",
        "plt.imshow(neg_data[0,:,:], cmap='binary')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RUXzYRyiCxXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gather the samples from the two classes into one matrix X\n",
        "# Note that there the samples from each class are appended \n",
        "# to make up 1872 samples altogether\n",
        "\n",
        "X = np.concatenate((pos_data, neg_data), axis=0)/255\n",
        "X = np.reshape(X, (X.shape[0],-1))\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "WZyLNgUqDiom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label the two classes with 1 and -1 respectively\n",
        "Y = np.concatenate((np.ones(pos_data.shape[0]), -np.ones(neg_data.shape[0])), axis=0);\n",
        "print(Y.shape)\n",
        "print(Y[0:10])\n",
        "print(Y[981:991])"
      ],
      "metadata": {
        "id": "yrwCPF95X1Ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose random samples from data. To do so:\n",
        "# permute data samples to run the learning  algorithm \n",
        "# and take just n_samples from the permuted data (here 60 samples)\n",
        "\n",
        "n_samples = 60\n",
        "\n",
        "p_idx = np.random.permutation(X.shape[0])\n",
        "X = X[p_idx[0:n_samples], :]\n",
        "Y = Y[p_idx[0:n_samples]]"
      ],
      "metadata": {
        "id": "NaGL66QfFPxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Project the data onto the means of the two classes\n",
        "# First look at the mean of the two class\n",
        "\n",
        "plt.imshow(np.reshape(np.mean(X[Y == 1, :], axis=0),(28,28)), cmap='binary')\n",
        "plt.show()\n",
        "\n",
        "# mean of second class\n",
        "plt.imshow(np.reshape(np.mean(X[Y == -1, :], axis=0),(28,28)), cmap='binary')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kQ5tvuvfIvXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now project the data\n",
        "\n",
        "V = np.stack((np.mean(X[Y == 1, :], axis=0), np.mean(X[Y == -1, :], axis=0)), axis=1)\n",
        "V[:, 0] = V[:, 0]/np.linalg.norm(V[:, 0])\n",
        "V[:, 1] = V[:, 1]/np.linalg.norm(V[:, 1])\n",
        "\n",
        "Z = np.matmul(X,V)\n",
        "print(Z.shape)\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.scatter(Z[Y == 1,0], Z[Y == 1,1], c='g')\n",
        "plt.scatter(Z[Y == -1,0], Z[Y == -1,1], c='r')"
      ],
      "metadata": {
        "id": "wUYaXWVXI7GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a helper function that plots the partition.\n",
        "\n",
        "def display2DPartition(Z, Y, w, b):\n",
        "  plt.figure(figsize=(5,5))\n",
        "  ax = plt.axes()\n",
        "  plt.scatter(Z[Y == 1,0], Z[Y == 1,1], c='g', zorder=1)\n",
        "  plt.scatter(Z[Y == -1,0], Z[Y == -1,1], c='r', zorder=2)\n",
        "  ax.set_facecolor('pink')\n",
        "  x = ax.get_xlim()\n",
        "  y = ax.get_ylim()\n",
        "  y_line = -(np.array(x)*w[0]+b)/w[1]\n",
        "  plt.fill_between(x,y_line, color='palegreen',zorder=0)\n",
        "  for iSmp in range(Z.shape[0]):\n",
        "    z_i = Z[iSmp, :]\n",
        "    # compute prediction with current w and b\n",
        "    f_i = np.sign(np.dot(w, z_i) + b)\n",
        "    if f_i != Y[iSmp]:\n",
        "      plt.scatter(z_i[0], z_i[1], marker='o', s=100, facecolors='none',linewidths=2, edgecolors='black', zorder=3)\n",
        "  ax.set_xlim(x)\n",
        "  ax.set_ylim(y)"
      ],
      "metadata": {
        "id": "bFsiRnSLUvg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Learning algorithm for Perceptron\n",
        "# here we denote two classes: the positive class by label \"1\"  and the negative\n",
        "# class by label \"-1.\" \n",
        "# Any point in the plane colored as green will be classified as positive\n",
        "# class and any point falling within the red region as negative class.\n",
        "# Training samples are denoted by the green crosses (positive) and red dots\n",
        "# (negative). A missclassified training point, that is \"f_i != y_i\" is \n",
        "# marked with a circle \n",
        "\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "# first initialize the parameters\n",
        "lr = 1                           # Learning rate parameter (1 in the classic perceptron algorithm)\n",
        "w = np.random.randn(Z.shape[1])  # Initial guess for the hyperplane parameters\n",
        "print(w)\n",
        "b = 0                            # bias is initially zero\n",
        "print(b)\n",
        "max_epoch = 100                  # Number of epoch (complete loops trough all data)\n",
        "epoch = 1                        # epoch counter\n",
        "\n",
        "# display the starting decision hyhyperplane (partition of the space)\n",
        "# (compare this to the decision hyperplane that is learned!)\n",
        "display2DPartition(Z, Y, w, b)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PIwaTs4TKh5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now run the perceptron training\n",
        "while epoch <= max_epoch:\n",
        "  # loop trough all data points one time (an epoch)\n",
        "  for iSmp in range(n_samples):\n",
        "    z_i = Z[iSmp, :]\n",
        "    # compute prediction with current w and b\n",
        "    f_i = np.sign(np.dot(w, z_i) + b)\n",
        "    # update w and b if missclassified\n",
        "    if f_i != Y[iSmp]:\n",
        "      # TODO: update the w and b according to the equation.\n",
        "      # Note that the notation here is different from the introduction.\n",
        "      w = w + lr * Y[iSmp] * z_i,
        "      b = b + lr * Y[iSmp],
        "  # diplay current decision hyperplane (partition of the space)\n",
        "  clear_output(wait=True)\n",
        "  display2DPartition(Z, Y, w, b)\n",
        "  plt.show()\n",
        "  time.sleep(0.1)\n",
        "  epoch = epoch + 1;"
      ],
      "metadata": {
        "id": "kkbK3arswD5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display the learned decision hyperplane (partition of the space)\n",
        "print(w)\n",
        "print(b)\n",
        "display2DPartition(Z, Y, w, b)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NXWubLSvxNXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise: \n",
        "1) Complete the training code to update w and b.\n",
        "\n",
        "2) After trying the code for the given classes,\n",
        "try running the code again, but this time changing the digits of the\n",
        "positive or negative class. \n",
        "You can do this by changing the following two lines above:\n",
        "\n",
        "pos_class = 0\n",
        "\n",
        "neg_class = 5\n",
        "\n",
        "What classes are easier to learn?\n"
      ],
      "metadata": {
        "id": "GrdBZveBUbgb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "owrnRay3gkuh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
